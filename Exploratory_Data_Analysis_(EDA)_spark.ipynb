{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyulianton/BigData/blob/main/Exploratory_Data_Analysis_(EDA)_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrodDrjMel3u",
        "outputId": "720ecec8-d625-4a07-feff-c53d42a46b22"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 126102 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u452-ga~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u452-ga~us1-0ubuntu1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u452-ga~us1-0ubuntu1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u452-ga~us1-0ubuntu1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u452-ga~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u452-ga~us1-0ubuntu1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://downloads.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUwNFp2ve1tr",
        "outputId": "1a8a78aa-4f2c-4d0b-f446-40ad24684272"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-10 13:56:47--  https://downloads.apache.org/spark/spark-3.5.5/spark-3.5.5-bin-hadoop3.tgz\n",
            "Resolving downloads.apache.org (downloads.apache.org)... 135.181.214.104, 88.99.208.237, 2a01:4f9:3a:2c57::2, ...\n",
            "Connecting to downloads.apache.org (downloads.apache.org)|135.181.214.104|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 400724056 (382M) [application/x-gzip]\n",
            "Saving to: ‘spark-3.5.5-bin-hadoop3.tgz’\n",
            "\n",
            "spark-3.5.5-bin-had 100%[===================>] 382.16M  24.1MB/s    in 17s     \n",
            "\n",
            "2025-05-10 13:57:04 (22.3 MB/s) - ‘spark-3.5.5-bin-hadoop3.tgz’ saved [400724056/400724056]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xf spark-3.5.5-bin-hadoop3.tgz"
      ],
      "metadata": {
        "id": "Og_EsvT3fEMT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.5-bin-hadoop3\""
      ],
      "metadata": {
        "id": "YgUbF7_XfMZm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install findspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eZN7xX-fRNN",
        "outputId": "08ac6d01-25ca-4df3-aa91-c02d415328fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena dataset dari scikit-learn terlalu kecil untuk didemonstrasikan dengan Spark (yang dirancang untuk data yang tidak muat di satu mesin), kita akan:\n",
        "1.  Buat dataset sintetis yang ukurannya *lebih besar* (dengan mereplikasi data scikit-learn berkali-kali).\n",
        "2.  Simpan dataset sintetis ini ke format Parquet, yang merupakan format umum dan efisien untuk Big Data di ekosistem Spark.\n",
        "3.  Baca data dari file Parquet ini ke dalam Spark DataFrame.\n",
        "4.  Demonstrasikan operasi EDA menggunakan Spark DataFrame API dan Spark SQL.\n",
        "5.  Jelaskan bagaimana visualisasi biasanya dilakukan *setelah* Spark melakukan agregasi atau sampling.\n",
        "\n",
        "Pastikan Anda sudah menginstal PySpark (`pip install pyspark pandas numpy scikit-learn`) dan memiliki Spark yang dapat diakses."
      ],
      "metadata": {
        "id": "M1i_a_HEbiiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import library yang dibutuhkan\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_diabetes\n",
        "import random\n",
        "import os # Untuk menyimpan file lokal\n",
        "\n",
        "# Import PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, count, when, isnan, floor, avg, stddev, percentile_approx, corr\n",
        "from pyspark.sql.types import DoubleType # Untuk simulasi missing values\n",
        "\n",
        "# --- Inisialisasi Spark Session ---\n",
        "# Ini adalah titik masuk untuk menggunakan fungsionalitas Spark\n",
        "print(\"Menginisialisasi Spark Session...\")\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"BigData_EDA_Spark_Example\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .config(\"spark.driver.memory\", \"4g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"Spark Session berhasil diinisialisasi.\")\n",
        "\n",
        "# --- Buat Dataset Sintetis Skala Lebih Besar ---\n",
        "# Dataset scikit-learn terlalu kecil. Kita buat versi \"Big Data\" dengan replikasi.\n",
        "# Dalam skenario nyata, data Anda sudah dalam format Big Data di HDFS/S3/dll.\n",
        "print(\"\\nMembuat dataset sintetis yang lebih besar (dengan mereplikasi data diabetes)...\")\n",
        "diabetes = load_diabetes()\n",
        "data_small_pandas = pd.DataFrame(diabetes.data, columns=diabetes.feature_names)\n",
        "target_small_pandas = pd.DataFrame(diabetes.target, columns=['target'])\n",
        "df_small_pandas = pd.concat([data_small_pandas, target_small_pandas], axis=1)\n",
        "\n",
        "# Replikasi data berkali-kali untuk mensimulasikan ukuran besar\n",
        "replication_factor = 10000 # Dataset asli 442 baris -> 4.42 juta baris\n",
        "df_large_pandas = pd.concat([df_small_pandas] * replication_factor, ignore_index=True)\n",
        "\n",
        "# Tambahkan missing values (simulasi)\n",
        "print(\"Mensimulasikan missing values di dataset sintetis...\")\n",
        "for col_name in ['bmi', 'bp', 's1', 'target']:\n",
        "    # Ambil indeks acak sebanyak 1% dari total baris\n",
        "    missing_indices = np.random.choice(df_large_pandas.index, size=int(len(df_large_pandas) * 0.01), replace=False)\n",
        "    df_large_pandas.loc[missing_indices, col_name] = np.nan\n",
        "\n",
        "# Simpan ke file Parquet\n",
        "parquet_path = \"./synthetic_diabetes.parquet\"\n",
        "print(f\"Menyimpan dataset sintetis ke {parquet_path}...\")\n",
        "df_large_pandas.to_parquet(parquet_path)\n",
        "\n",
        "print(f\"Dataset sintetis ({len(df_large_pandas)} baris) berhasil dibuat dan disimpan.\")\n",
        "\n",
        "# --- Load Data ke Spark DataFrame ---\n",
        "# Ini adalah cara membaca data Big Data ke Spark\n",
        "print(f\"\\nMemuat dataset dari file Parquet ({parquet_path}) ke Spark DataFrame...\")\n",
        "spark_df = spark.read.parquet(parquet_path)\n",
        "\n",
        "print(\"\\nSpark DataFrame berhasil dimuat.\")\n",
        "#spark_df.printSchema() # Bisa cek skema Spark\n",
        "spark_df.show(5) # Tampilkan 5 baris pertama (diambil dari partisi manapun, hanya sampel)\n",
        "print(f\"Total baris di Spark DataFrame (dihitung terdistribusi): {spark_df.count()}\")\n",
        "\n",
        "# Hapus file lokal sintetis jika tidak lagi diperlukan\n",
        "# os.remove(parquet_path) # Opsional: Hapus setelah dibaca\n",
        "# os.remove(parquet_path + \"/_SUCCESS\") # Jika Spark menulis file _SUCCESS"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menginisialisasi Spark Session...\n",
            "Spark Session berhasil diinisialisasi.\n",
            "\n",
            "Membuat dataset sintetis yang lebih besar (dengan mereplikasi data diabetes)...\n",
            "Mensimulasikan missing values di dataset sintetis...\n",
            "Menyimpan dataset sintetis ke ./synthetic_diabetes.parquet...\n",
            "Dataset sintetis (4420000 baris) berhasil dibuat dan disimpan.\n",
            "\n",
            "Memuat dataset dari file Parquet (./synthetic_diabetes.parquet) ke Spark DataFrame...\n",
            "\n",
            "Spark DataFrame berhasil dimuat.\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "|                 age|                 sex|                 bmi|                  bp|                  s1|                  s2|                  s3|                  s4|                  s5|                  s6|target|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "|0.038075906433423026| 0.05068011873981862|0.061696206518683294|  0.0218723855140367|-0.04422349842444599|-0.03482076283769895|-0.04340084565202491|-0.00259226199818...|0.019907486170462722|-0.01764612515980379| 151.0|\n",
            "|-0.00188201652779...|-0.04464163650698...|-0.05147406123880...|-0.02632752814785296|-0.00844872411121...|-0.01916333974822...| 0.07441156407875721|-0.03949338287409329| -0.0683315470939731|  -0.092204049626824|  75.0|\n",
            "| 0.08529890629667548| 0.05068011873981862| 0.04445121333659049|-0.00567042229275739|-0.04559945128264711|-0.03419446591411989|-0.03235593223976409|-0.00259226199818...|0.002861309289833047|-0.02593033898947...| 141.0|\n",
            "| -0.0890629393522567|-0.04464163650698...|-0.01159501450521...|-0.03665608107540074| 0.01219056876179996| 0.02499059336410222|-0.03603757004385...| 0.03430885887772673|0.022687744966501246|-0.00936191133013...| 206.0|\n",
            "|0.005383060374248237|-0.04464163650698...|-0.03638469220446948|  0.0218723855140367|0.003934851612593237|0.015596139510416171|0.008142083605192267|-0.00259226199818...|-0.03198763948805312|-0.04664087356364498| 135.0|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Total baris di Spark DataFrame (dihitung terdistribusi): 4420000\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl9FQpQNbiiT",
        "outputId": "8cba470e-c12e-45cb-da66-a3edb90ee2ce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Contoh Program 1: Ringkasan Statistik Dasar (Menggunakan Spark DataFrame)**\n",
        "\n",
        "Kita akan menghitung statistik deskriptif pada *seluruh* Spark DataFrame yang (secara konseptual) berukuran besar."
      ],
      "metadata": {
        "id": "jE8d6PKtbiiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Contoh 1: Ringkasan Statistik Dasar (Spark DataFrame di Data Terdistribusi) ---\")\n",
        "\n",
        "# Menggunakan .describe() atau .summary() pada Spark DataFrame\n",
        "# Ini menghitung statistik secara terdistribusi.\n",
        "print(\"\\nStatistik deskriptif kolom numerik (Spark DataFrame .describe()):\")\n",
        "spark_df.describe(['bmi', 'bp', 'target']).show()\n",
        "\n",
        "# .summary() memberikan statistik yang lebih kaya, termasuk persentil (aproksimasi)\n",
        "print(\"\\nRingkasan statistik (Spark DataFrame .summary()):\")\n",
        "spark_df.summary().show()\n",
        "\n",
        "# Menghitung statistik spesifik menggunakan Spark SQL functions\n",
        "# Ini dieksekusi secara terdistribusi di seluruh klaster.\n",
        "# Untuk median/percentile, gunakan percentile_approx untuk efisiensi di Big Data\n",
        "print(f\"\\nRata-rata BMI (Spark): {spark_df.select(avg('bmi')).collect()[0][0]:.2f}\") # collect() mengambil hasil ke driver\n",
        "print(f\"Standard Deviasi Tekanan Darah (Spark): {spark_df.select(stddev('bp')).collect()[0][0]:.2f}\")\n",
        "\n",
        "# Menghitung Median (Percentil ke-50) dan Percentil ke-75 secara aproksimasi di Spark\n",
        "# percentile_approx(column, percentage, accuracy - optional)\n",
        "approx_quantiles_target = spark_df.stat.approxQuantile('target', [0.5, 0.75], 0.01) # akurasi 0.01\n",
        "median_target_spark = approx_quantiles_target[0]\n",
        "q3_target_spark = approx_quantiles_target[1]\n",
        "\n",
        "print(f\"Median Target (Spark, aproksimasi): {median_target_spark:.2f}\")\n",
        "print(f\"Percentil ke-75 Target (Spark, aproksimasi): {q3_target_spark:.2f}\")\n",
        "\n",
        "# Untuk menghitung modus (nilai paling sering) per kolom di Spark\n",
        "# spark_df.groupBy(\"nama_kolom_kategori\").count().orderBy(col(\"count\").desc()).show()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Contoh 1: Ringkasan Statistik Dasar (Spark DataFrame di Data Terdistribusi) ---\n",
            "\n",
            "Statistik deskriptif kolom numerik (Spark DataFrame .describe()):\n",
            "+-------+--------------------+--------------------+------------------+\n",
            "|summary|                 bmi|                  bp|            target|\n",
            "+-------+--------------------+--------------------+------------------+\n",
            "|  count|             4375800|             4375800|           4375800|\n",
            "|   mean|-1.44314204073557...|-3.06722789341444...|152.13737830796654|\n",
            "| stddev|0.047564388061949896|0.047562564417359475| 77.00644191341371|\n",
            "|    min|-0.09027529589850945|-0.11239880254408448|              25.0|\n",
            "|    max| 0.17055522598064407| 0.13204361674121307|             346.0|\n",
            "+-------+--------------------+--------------------+------------------+\n",
            "\n",
            "\n",
            "Ringkasan statistik (Spark DataFrame .summary()):\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "|summary|                 age|                 sex|                 bmi|                  bp|                  s1|                  s2|                  s3|                  s4|                  s5|                  s6|            target|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "|  count|             4420000|             4420000|             4375800|             4375800|             4375800|             4420000|             4420000|             4420000|             4420000|             4420000|           4375800|\n",
            "|   mean|-1.15875132515854...|2.563158333141390...|-1.44314204073557...|-3.06722789341444...|-9.42394697217908...|3.923568358094068...|-6.02843566921066...|-1.79825234642662...|9.233202437913486...|1.343545686972285...|152.13737830796654|\n",
            "| stddev|0.047565154796123076| 0.04756515479612352|0.047564388061949896|0.047562564417359475| 0.04756256703237929|0.047565154796121924| 0.04756515479612207| 0.04756515479612377|0.047565154796122354| 0.04756515479612436| 77.00644191341371|\n",
            "|    min| -0.1072256316073538|-0.04464163650698...|-0.09027529589850945|-0.11239880254408448|-0.12678066991651324|-0.11561306597939897|-0.10230705051741597| -0.0763945037500033|-0.12609712083330468|-0.13776722569000302|              25.0|\n",
            "|    25%|-0.03820740103798481|-0.04464163650698...|-0.03422906805670789|-0.03665608107540074|-0.03459182841703...|-0.03043668437264...|-0.03603757004385...|-0.03949338287409329|-0.03324559264822791|-0.03421455281914162|              87.0|\n",
            "|    50%|0.005383060374248237|-0.04464163650698...|-0.00728376620968...|-0.00567042229275739|-0.00432086553661...|-0.00381906512053...|-0.00658446761115...|-0.00259226199818...|-0.00149594875772...|-0.00107769750046...|             141.0|\n",
            "|    75%|0.038075906433423026| 0.05068011873981862|0.031517468450020895| 0.03564378941743375|0.028702003060213414| 0.03000096875273476|0.030231910429713918| 0.03430885887772673| 0.03243232415655107|0.027917050903375224|             212.0|\n",
            "|    max| 0.11072667545381144| 0.05068011873981862| 0.17055522598064407| 0.13204361674121307| 0.15391371315651542| 0.19878798965729408| 0.18117906039727852| 0.18523444326019867| 0.13359728192191356| 0.13561183068907107|             346.0|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+\n",
            "\n",
            "\n",
            "Rata-rata BMI (Spark): -0.00\n",
            "Standard Deviasi Tekanan Darah (Spark): 0.05\n",
            "Median Target (Spark, aproksimasi): 140.00\n",
            "Percentil ke-75 Target (Spark, aproksimasi): 214.00\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Beg6lK7obiiX",
        "outputId": "33a0106f-04f0-4eef-a42a-9074910b7922"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Contoh Program 2: Visualisasi Distribusi Data (Menggunakan Spark untuk Agregasi, Visualisasi di Luar)**\n",
        "\n",
        "Spark digunakan untuk menghitung data yang dibutuhkan untuk visualisasi (misalnya, jumlah per bin untuk histogram). Visualisasi *itu sendiri* biasanya dilakukan menggunakan library lain (Pandas/Matplotlib/Seaborn) setelah mengumpulkan data ringkasan, atau menggunakan tool BI yang terhubung ke Spark."
      ],
      "metadata": {
        "id": "qNkZC1J6biiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Contoh 2: Visualisasi Distribusi Data (Spark untuk Agregasi, Visualisasi di Luar) ---\")\n",
        "\n",
        "# Membuat data untuk Histogram 'bmi' menggunakan Agregasi di Spark\n",
        "# Tentukan ukuran bin\n",
        "bin_size = 0.05 # Ukuran bin sebagai float Python\n",
        "\n",
        "# Import lit function (pastikan sudah diimpor di bagian atas program)\n",
        "# from pyspark.sql.functions import lit, col, floor # atau cast\n",
        "\n",
        "# Langkah Perbaikan Terakhir: Hitung nilai bin sebagai kolom baru terlebih dahulu\n",
        "# Menggunakan pendekatan .cast(\"int\")\n",
        "spark_df_with_bins = spark_df.withColumn(\n",
        "    \"bmi_bin\",\n",
        "    (col(\"bmi\")/lit(bin_size)).cast(\"int\") * lit(bin_size)\n",
        ")\n",
        "\n",
        "# Atau jika ingin coba lagi dengan floor() sebagai alternatif untuk nilai bin\n",
        "# spark_df_with_bins = spark_df.withColumn(\n",
        "#     \"bmi_bin\",\n",
        "#     floor(col(\"bmi\")/lit(bin_size)) * lit(bin_size)\n",
        "# )\n",
        "\n",
        "\n",
        "# Sekarang, lakukan grouping berdasarkan nama kolom baru \"bmi_bin\"\n",
        "print(\"\\nMelakukan grouping berdasarkan kolom bin yang baru dibuat...\")\n",
        "bmi_hist_spark = spark_df_with_bins.groupBy(\"bmi_bin\").count().orderBy(\"bmi_bin\") # Urutkan berdasarkan bin itu sendiri untuk plot\n",
        "\n",
        "print(\"\\nData agregasi per bin untuk Histogram BMI (Spark):\")\n",
        "# Menggunakan .show(n=n, truncate=False) agar nilai bin yang diplot tidak terpotong jika terlalu panjang\n",
        "# Nama kolom bin sekarang seharusnya \"bmi_bin\"\n",
        "bmi_hist_spark.show(5, truncate=False)\n",
        "\n",
        "# Mengumpulkan HASIL AGREGASI ke Pandas untuk Visualisasi\n",
        "# HATI-HATI: Gunakan .toPandas() hanya jika hasil agregasi CUKUP KECIL\n",
        "print(\"\\nMengumpulkan hasil agregasi ke Pandas (Spark .toPandas())...\")\n",
        "try:\n",
        "    bmi_hist_pandas = bmi_hist_spark.toPandas()\n",
        "\n",
        "    # Visualisasi Histogram menggunakan Matplotlib/Seaborn pada data yang sudah diagregasi\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    # Nama kolom bin di Pandas DataFrame hasil .toPandas() akan sesuai dengan nama kolom baru di Spark\n",
        "    plt.bar(bmi_hist_pandas[\"bmi_bin\"], bmi_hist_pandas['count'], width=bin_size * 0.9)\n",
        "    plt.title('Distribusi BMI (Histogram dari Agregasi Spark)')\n",
        "    plt.xlabel('BMI (Bin)')\n",
        "    plt.ylabel('Frekuensi')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Gagal mengumpulkan data agregasi ke Pandas karena ukuran terlalu besar atau error: {e}\")\n",
        "    print(\"Visualisasi langsung dari Spark tidak umum; biasanya pakai tools BI atau library khusus.\")\n",
        "# Visualisasi KDE dari Big Data:\n",
        "# KDE plot langsung dari seluruh Big Data sangat mahal dan tidak umum.\n",
        "# Biasanya, KDE dihitung dari SAMPEL data (menggunakan .sample() di Spark, lalu .toPandas() untuk sampelnya)\n",
        "# atau menggunakan algoritma estimasi densitas yang dirancang untuk skala besar.\n",
        "\n",
        "# Contoh mendapatkan sampel untuk visualisasi KDE\n",
        "# spark_df_sample = spark_df.sample(fraction=0.001, seed=42) # Ambil 0.1% sampel\n",
        "# try:\n",
        "#     df_sample_pandas_for_kde = spark_df_sample.toPandas()\n",
        "#     plt.figure(figsize=(8, 6))\n",
        "#     sns.kdeplot(df_sample_pandas_for_kde['bmi'], fill=True)\n",
        "#     plt.title('Estimasi Densitas Kernel BMI (dari Sampel Spark)')\n",
        "#     plt.xlabel('BMI')\n",
        "#     plt.ylabel('Densitas')\n",
        "#     plt.show()\n",
        "# except Exception as e:\n",
        "#      print(f\"Gagal mengumpulkan sampel untuk KDE: {e}\")\n",
        "\n",
        "# --- Koneksi ke Big Data ---\n",
        "# Tools BI seperti Tableau, Superset, Looker bisa terhubung langsung ke Spark\n",
        "# dan melakukan operasi agregasi/filter yang diperlukan di backend, lalu memvisualisasikannya.\n",
        "# Library seperti Datashader (dengan backend Dask atau RAPIDS, bisa diintegrasikan dengan Spark)\n",
        "# dirancang untuk memvisualisasikan miliaran titik data dengan melakukan rasterisasi (binning ke piksel)."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Contoh 2: Visualisasi Distribusi Data (Spark untuk Agregasi, Visualisasi di Luar) ---\n",
            "\n",
            "Melakukan grouping berdasarkan kolom bin yang baru dibuat...\n",
            "\n",
            "Data agregasi per bin untuk Histogram BMI (Spark):\n",
            "+-------+-------+\n",
            "|bmi_bin|count  |\n",
            "+-------+-------+\n",
            "|NULL   |44200  |\n",
            "|-0.05  |613784 |\n",
            "|0.0    |3039325|\n",
            "|0.05   |603951 |\n",
            "|0.1    |98925  |\n",
            "+-------+-------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Mengumpulkan hasil agregasi ke Pandas (Spark .toPandas())...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "GjSJXjlXbiiY",
        "outputId": "d8b332ca-791c-4635-ecd8-f2160eb38f62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Contoh Program 3: Analisis Missing Values (Menggunakan Spark DataFrame)**\n",
        "\n",
        "Mengecek dan menangani missing values dilakukan menggunakan operasi Spark DataFrame yang berjalan terdistribusi."
      ],
      "metadata": {
        "id": "WVjLFf6abiiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Contoh 3: Analisis Missing Values (Spark DataFrame di Data Terdistribusi) ---\")\n",
        "\n",
        "# Mengecek jumlah missing values per kolom di SELURUH Spark DataFrame\n",
        "# Menggunakan fungsi agregasi COUNT() dengan kondisi IS NULL atau ISNAN\n",
        "print(\"\\nJumlah missing values per kolom di Spark DataFrame:\")\n",
        "\n",
        "# Cara 1: Menggunakan SQL Expression string di select\n",
        "# requires `from pyspark.sql.functions import expr` if not already imported\n",
        "# spark_df.select([expr(f\"count(CASE WHEN {c} IS NULL THEN 1 END)\").alias(c + \"_missing\") for c in spark_df.columns]).show()\n",
        "\n",
        "# Cara 2: Menggunakan DataFrame functions (lebih PySparkic)\n",
        "# requires `from pyspark.sql.functions import col, count, when, isnan`\n",
        "missing_counts = spark_df.select([count(when(col(c).isNull() | isnan(c), c)).alias(c + \"_missing\") for c in spark_df.columns])\n",
        "missing_counts.show()\n",
        "\n",
        "# Menangani missing values di Spark DataFrame:\n",
        "# .na.drop() untuk menghapus baris dengan missing values\n",
        "# Menghapus di Big Data berpotensi kehilangan banyak data jika tidak hati-hati\n",
        "print(\"\\nSpark DataFrame setelah menghapus baris dengan missing BMI:\")\n",
        "spark_df_dropped = spark_df.na.drop(subset=['bmi'])\n",
        "print(f\"Jumlah baris setelah menghapus baris dengan missing BMI (dihitung terdistribusi): {spark_df_dropped.count()} (dari {spark_df.count()})\")\n",
        "spark_df_dropped.show(5) # Tampilkan sampel hasilnya\n",
        "\n",
        "# .na.fill() untuk mengisi missing values\n",
        "# Rata-rata (atau nilai pengisi lain) harus dihitung dari data asli (jika perlu)\n",
        "# Hitung rata-rata BMI dari data ASLI (bukan sampel atau data yang sudah dihapus missingnya jika itu bukan tujuan)\n",
        "mean_bmi_spark = spark_df.select(avg('bmi')).collect()[0][0]\n",
        "print(f\"\\nRata-rata BMI dari seluruh Spark DataFrame: {mean_bmi_spark:.2f}\")\n",
        "\n",
        "# Isi missing BMI dengan rata-rata yang dihitung secara terdistribusi\n",
        "spark_df_filled = spark_df.na.fill({'bmi': mean_bmi_spark})\n",
        "print(\"\\nSpark DataFrame setelah mengisi missing BMI dengan rata-rata:\")\n",
        "# Cek lagi missing count untuk BMI - seharusnya 0\n",
        "spark_df_filled.select(count(when(col(\"bmi\").isNull() | isnan(col(\"bmi\")), \"bmi\")).alias(\"bmi_missing\")).show()\n",
        "spark_df_filled.show(5) # Tampilkan sampel hasilnya\n",
        "\n",
        "# --- Koneksi ke Big Data ---\n",
        "# Pola missingness (heatmap) visualisasi langsung dari Spark DataFrame mentah berukuran besar sulit.\n",
        "# Biasanya dicek dari hitungan missing per kolom seperti di atas, atau dicek di sampel data."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Contoh 3: Analisis Missing Values (Spark DataFrame di Data Terdistribusi) ---\n",
            "\n",
            "Jumlah missing values per kolom di Spark DataFrame:\n",
            "+-----------+-----------+-----------+----------+----------+----------+----------+----------+----------+----------+--------------+\n",
            "|age_missing|sex_missing|bmi_missing|bp_missing|s1_missing|s2_missing|s3_missing|s4_missing|s5_missing|s6_missing|target_missing|\n",
            "+-----------+-----------+-----------+----------+----------+----------+----------+----------+----------+----------+--------------+\n",
            "|          0|          0|      44200|     44200|     44200|         0|         0|         0|         0|         0|         44200|\n",
            "+-----------+-----------+-----------+----------+----------+----------+----------+----------+----------+----------+--------------+\n",
            "\n",
            "\n",
            "Spark DataFrame setelah menghapus baris dengan missing BMI:\n",
            "Jumlah baris setelah menghapus baris dengan missing BMI (dihitung terdistribusi): 4375800 (dari 4420000)\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "|                 age|                 sex|                 bmi|                  bp|                  s1|                  s2|                  s3|                  s4|                  s5|                  s6|target|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "|0.038075906433423026| 0.05068011873981862|0.061696206518683294|  0.0218723855140367|-0.04422349842444599|-0.03482076283769895|-0.04340084565202491|-0.00259226199818...|0.019907486170462722|-0.01764612515980379| 151.0|\n",
            "|-0.00188201652779...|-0.04464163650698...|-0.05147406123880...|-0.02632752814785296|-0.00844872411121...|-0.01916333974822...| 0.07441156407875721|-0.03949338287409329| -0.0683315470939731|  -0.092204049626824|  75.0|\n",
            "| 0.08529890629667548| 0.05068011873981862| 0.04445121333659049|-0.00567042229275739|-0.04559945128264711|-0.03419446591411989|-0.03235593223976409|-0.00259226199818...|0.002861309289833047|-0.02593033898947...| 141.0|\n",
            "| -0.0890629393522567|-0.04464163650698...|-0.01159501450521...|-0.03665608107540074| 0.01219056876179996| 0.02499059336410222|-0.03603757004385...| 0.03430885887772673|0.022687744966501246|-0.00936191133013...| 206.0|\n",
            "|0.005383060374248237|-0.04464163650698...|-0.03638469220446948|  0.0218723855140367|0.003934851612593237|0.015596139510416171|0.008142083605192267|-0.00259226199818...|-0.03198763948805312|-0.04664087356364498| 135.0|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Rata-rata BMI dari seluruh Spark DataFrame: -0.00\n",
            "\n",
            "Spark DataFrame setelah mengisi missing BMI dengan rata-rata:\n",
            "+-----------+\n",
            "|bmi_missing|\n",
            "+-----------+\n",
            "|          0|\n",
            "+-----------+\n",
            "\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "|                 age|                 sex|                 bmi|                  bp|                  s1|                  s2|                  s3|                  s4|                  s5|                  s6|target|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "|0.038075906433423026| 0.05068011873981862|0.061696206518683294|  0.0218723855140367|-0.04422349842444599|-0.03482076283769895|-0.04340084565202491|-0.00259226199818...|0.019907486170462722|-0.01764612515980379| 151.0|\n",
            "|-0.00188201652779...|-0.04464163650698...|-0.05147406123880...|-0.02632752814785296|-0.00844872411121...|-0.01916333974822...| 0.07441156407875721|-0.03949338287409329| -0.0683315470939731|  -0.092204049626824|  75.0|\n",
            "| 0.08529890629667548| 0.05068011873981862| 0.04445121333659049|-0.00567042229275739|-0.04559945128264711|-0.03419446591411989|-0.03235593223976409|-0.00259226199818...|0.002861309289833047|-0.02593033898947...| 141.0|\n",
            "| -0.0890629393522567|-0.04464163650698...|-0.01159501450521...|-0.03665608107540074| 0.01219056876179996| 0.02499059336410222|-0.03603757004385...| 0.03430885887772673|0.022687744966501246|-0.00936191133013...| 206.0|\n",
            "|0.005383060374248237|-0.04464163650698...|-0.03638469220446948|  0.0218723855140367|0.003934851612593237|0.015596139510416171|0.008142083605192267|-0.00259226199818...|-0.03198763948805312|-0.04664087356364498| 135.0|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpSua2Mvbiia",
        "outputId": "c09615fb-8399-40e8-dbbe-cf5486667ac7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Contoh Program 4: Analisis Hubungan (Korelasi Menggunakan Spark DataFrame)**\n",
        "\n",
        "Spark dapat menghitung korelasi antar kolom atau matriks korelasi secara terdistribusi."
      ],
      "metadata": {
        "id": "Z9L0fNaTbiib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Contoh 4: Analisis Hubungan (Korelasi di Spark DataFrame) ---\")\n",
        "\n",
        "# Menghitung Korelasi antar dua kolom spesifik di SELURUH Spark DataFrame\n",
        "# Menggunakan .stat.corr(col1, col2) atau .corr(col1, col2)\n",
        "# Kedua sintaks ini biasanya sinonim dan bekerja untuk pasangan kolom.\n",
        "correlation_bmi_target = spark_df.stat.corr(\"bmi\", \"target\")\n",
        "print(f\"\\nKorelasi Pearson antara BMI dan Target (Spark): {correlation_bmi_target:.2f}\")\n",
        "\n",
        "# Hitung korelasi untuk beberapa pasangan lain yang menarik di dataset ini\n",
        "correlation_bmi_bp = spark_df.stat.corr(\"bmi\", \"bp\")\n",
        "correlation_s1_s2 = spark_df.stat.corr(\"s1\", \"s2\")\n",
        "correlation_target_bp = spark_df.stat.corr(\"target\", \"bp\")\n",
        "\n",
        "\n",
        "print(f\"Korelasi Pearson antara BMI dan Tekanan Darah (Spark): {correlation_bmi_bp:.2f}\")\n",
        "print(f\"Korelasi Pearson antara S1 dan S2 (Spark): {correlation_s1_s2:.2f}\")\n",
        "print(f\"Korelasi Pearson antara Target dan Tekanan Darah (Spark): {correlation_target_bp:.2f}\")\n",
        "\n",
        "\n",
        "# --- Menghitung Matriks Korelasi Antar SEMUA Fitur (Penjelasan Konseptual & Kendala) ---\n",
        "print(\"\\n--- Matriks Korelasi Antar SEMUA Fitur (Penjelasan Kendala di Versi PySpark Ini) ---\")\n",
        "print(\"Menghitung matriks korelasi penuh antar semua kolom numerik menggunakan spark_df.corr() tanpa argumen\")\n",
        "print(\"menyebabkan error di versi PySpark ini karena fungsi tersebut mengharapkan 2 argumen kolom.\")\n",
        "print(\"Menghitung matriks korelasi penuh memerlukan pendekatan yang berbeda:\")\n",
        "\n",
        "print(\"1. Pendekatan Iteratif (Kurang Efisien untuk Banyak Kolom):\")\n",
        "print(\"   Melakukan loop untuk setiap pasangan kolom (col_i, col_j), memanggil spark_df.stat.corr(col_i, col_j),\")\n",
        "print(\"   dan mengumpulkan hasilnya untuk membangun matriks Pandas secara manual.\")\n",
        "print(\"   Ini membutuhkan banyak job Spark terpisah.\")\n",
        "# Contoh Kode Konseptual (tidak runnable sepenuhnya di sini tanpa logic loop lengkap & error handling):\n",
        "# numeric_cols = [c for c, dtype in spark_df.dtypes if dtype in ['double', 'float', 'int', 'long']]\n",
        "# # Pastikan tidak ada NaN yang bisa menyebabkan error pada corr() - mungkin perlu .na.drop() sementara\n",
        "# df_for_corr = spark_df.na.drop(subset=numeric_cols) # Drop baris dengan NaN di kolom numerik untuk korelasi\n",
        "# corr_data = []\n",
        "# for i in range(len(numeric_cols)):\n",
        "#     for j in range(i, len(numeric_cols)): # Hanya hitung segitiga atas\n",
        "#         col1 = numeric_cols[i]\n",
        "#         col2 = numeric_cols[j]\n",
        "#         # Hitung korelasi (ini memicu job Spark)\n",
        "#         correlation_value = df_for_corr.stat.corr(col1, col2)\n",
        "#         corr_data.append(((col1, col2), correlation_value))\n",
        "# # Dari corr_data, bangun matriks Pandas\n",
        "\n",
        "print(\"\\n2. Pendekatan Menggunakan spark.ml.stat.Correlation (Lebih Scalable, Tapi Perlu Feature Vector):\")\n",
        "print(\"   Menggunakan modul PySpark MLlib (pyspark.ml.stat.Correlation).\")\n",
        "print(\"   Ini adalah cara yang lebih skalabel, tetapi membutuhkan langkah tambahan:\")\n",
        "print(\"   - Menggabungkan semua kolom fitur numerik menjadi satu kolom 'Vector' menggunakan VectorAssembler.\")\n",
        "print(\"   - Memanggil Correlation.corr() pada DataFrame dengan kolom Vector tersebut.\")\n",
        "# Contoh Kode Konseptual (perlu import VectorAssembler dan Correlation):\n",
        "# from pyspark.ml.feature import VectorAssembler\n",
        "# from pyspark.ml.stat import Correlation\n",
        "# # Pilih kolom numerik\n",
        "# numeric_cols_ml = [c for c, dtype in spark_df.dtypes if dtype in ['double', 'float', 'int', 'long']] # Sesuaikan jika ada tipe lain\n",
        "# # Assembler untuk menggabungkan fitur\n",
        "# assembler = VectorAssembler(inputCols=numeric_cols_ml, outputCol=\"features\")\n",
        "# df_vector = assembler.transform(spark_df.na.drop(subset=numeric_cols_ml)) # Drop NaN untuk korelasi\n",
        "\n",
        "# # Hitung matriks korelasi Pearson pada kolom fitur vector\n",
        "# matrix = Correlation.corr(df_vector, \"features\", method=\"pearson\")\n",
        "\n",
        "# # Hasilnya adalah DataFrame dengan satu baris dan satu kolom Vector.\n",
        "# # Ambil Vector tersebut dan konversi ke array numpy untuk visualisasi heatmap di Pandas.\n",
        "# # matrix_np = matrix.collect()[0][0].toArray()\n",
        "# # matrix_pandas = pd.DataFrame(matrix_np, index=numeric_cols_ml, columns=numeric_cols_ml)\n",
        "# # Sekarang matrix_pandas bisa divisualisasikan pakai heatmap Seaborn.\n",
        "\n",
        "\n",
        "print(\"\\n--- Visualisasi Matriks Korelasi (Penjelasan Kendala) ---\")\n",
        "print(\"Visualisasi heatmap matriks korelasi penuh (MxM) juga punya tantangan:\")\n",
        "print(\"1. Jika jumlah kolom (M) sangat besar, matriksnya sendiri pun besar (MxM) dan sulit divisualisasikan.\")\n",
        "print(\"2. Jika matriks berhasil dihitung di Spark (misal pakai MLlib), hasilnya harus dikumpulkan ke driver\")\n",
        "print(\"   dan diubah ke format (misal Pandas DataFrame) untuk plotting pakai Matplotlib/Seaborn.\")\n",
        "print(\"   Ini hanya mungkin jika ukuran matriks M x M tidak terlalu besar.\")\n",
        "print(\"\\nUntuk EDA praktis di Big Data, seringkali kita fokus pada:\")\n",
        "print(\"- Korelasi antar fitur & target variabel saja (subset kolom).\")\n",
        "print(\"- Menggunakan tools BI yang bisa menghitung agregasi korelasi di backend.\")\n",
        "print(\"- Melakukan analisis korelasi di SAMPEL data menggunakan Pandas (seperti contoh sebelumnya).\")\n",
        "\n",
        "\n",
        "# Visualisasi Scatter Plot dari Big Data:\n",
        "# Seperti penjelasan sebelumnya, scatter plot langsung dari seluruh data mentah tidak praktis.\n",
        "# Lakukan scatter plot pada SAMPEL data (setelah spark_df.sample().toPandas()).\n",
        "# sns.scatterplot(x='bmi', y='target', data=df_sample_for_pandas) # Gunakan df_sample_for_pandas dari Contoh 6"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Contoh 4: Analisis Hubungan (Korelasi di Spark DataFrame) ---\n",
            "\n",
            "Korelasi Pearson antara BMI dan Target (Spark): 0.57\n",
            "Korelasi Pearson antara BMI dan Tekanan Darah (Spark): 0.39\n",
            "Korelasi Pearson antara S1 dan S2 (Spark): 0.89\n",
            "Korelasi Pearson antara Target dan Tekanan Darah (Spark): 0.43\n",
            "\n",
            "--- Matriks Korelasi Antar SEMUA Fitur (Penjelasan Kendala di Versi PySpark Ini) ---\n",
            "Menghitung matriks korelasi penuh antar semua kolom numerik menggunakan spark_df.corr() tanpa argumen\n",
            "menyebabkan error di versi PySpark ini karena fungsi tersebut mengharapkan 2 argumen kolom.\n",
            "Menghitung matriks korelasi penuh memerlukan pendekatan yang berbeda:\n",
            "1. Pendekatan Iteratif (Kurang Efisien untuk Banyak Kolom):\n",
            "   Melakukan loop untuk setiap pasangan kolom (col_i, col_j), memanggil spark_df.stat.corr(col_i, col_j),\n",
            "   dan mengumpulkan hasilnya untuk membangun matriks Pandas secara manual.\n",
            "   Ini membutuhkan banyak job Spark terpisah.\n",
            "\n",
            "2. Pendekatan Menggunakan spark.ml.stat.Correlation (Lebih Scalable, Tapi Perlu Feature Vector):\n",
            "   Menggunakan modul PySpark MLlib (pyspark.ml.stat.Correlation).\n",
            "   Ini adalah cara yang lebih skalabel, tetapi membutuhkan langkah tambahan:\n",
            "   - Menggabungkan semua kolom fitur numerik menjadi satu kolom 'Vector' menggunakan VectorAssembler.\n",
            "   - Memanggil Correlation.corr() pada DataFrame dengan kolom Vector tersebut.\n",
            "\n",
            "--- Visualisasi Matriks Korelasi (Penjelasan Kendala) ---\n",
            "Visualisasi heatmap matriks korelasi penuh (MxM) juga punya tantangan:\n",
            "1. Jika jumlah kolom (M) sangat besar, matriksnya sendiri pun besar (MxM) dan sulit divisualisasikan.\n",
            "2. Jika matriks berhasil dihitung di Spark (misal pakai MLlib), hasilnya harus dikumpulkan ke driver\n",
            "   dan diubah ke format (misal Pandas DataFrame) untuk plotting pakai Matplotlib/Seaborn.\n",
            "   Ini hanya mungkin jika ukuran matriks M x M tidak terlalu besar.\n",
            "\n",
            "Untuk EDA praktis di Big Data, seringkali kita fokus pada:\n",
            "- Korelasi antar fitur & target variabel saja (subset kolom).\n",
            "- Menggunakan tools BI yang bisa menghitung agregasi korelasi di backend.\n",
            "- Melakukan analisis korelasi di SAMPEL data menggunakan Pandas (seperti contoh sebelumnya).\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6NAUMpcbiic",
        "outputId": "deebf71c-3121-4f31-a63f-fa27255c383d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Contoh Program 5: Deteksi Outliers (Menggunakan Spark DataFrame)**\n",
        "\n",
        "Deteksi outliers yang melibatkan perhitungan statistik robust (seperti IQR) atau filtering dilakukan menggunakan Spark DataFrame."
      ],
      "metadata": {
        "id": "oaoQV2Vgbiid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Contoh 5: Deteksi Outliers (Spark DataFrame di Data Terdistribusi) ---\")\n",
        "\n",
        "# Deteksi outlier sederhana berdasarkan ambang batas IQR (Interquartile Range) di Spark\n",
        "# Perlu menghitung Q1 dan Q3 secara terdistribusi\n",
        "# Gunakan approxQuantile untuk efisiensi\n",
        "print(\"\\nMenghitung Q1 dan Q3 untuk BMI secara aproksimasi di Spark...\")\n",
        "try:\n",
        "    quantiles_bmi_spark = spark_df.stat.approxQuantile('bmi', [0.25, 0.75], 0.01)\n",
        "    Q1_spark = quantiles_bmi_spark[0]\n",
        "    Q3_spark = quantiles_bmi_spark[1]\n",
        "    IQR_spark = Q3_spark - Q1_spark\n",
        "\n",
        "    outlier_threshold_upper_spark = Q3_spark + 1.5 * IQR_spark\n",
        "    outlier_threshold_lower_spark = Q1_spark - 1.5 * IQR_spark\n",
        "\n",
        "    print(f\"Q1 BMI (Spark Aproksimasi): {Q1_spark:.2f}\")\n",
        "    print(f\"Q3 BMI (Spark Aproksimasi): {Q3_spark:.2f}\")\n",
        "    print(f\"IQR BMI: {IQR_spark:.2f}\")\n",
        "    print(f\"Batas Atas Outlier (1.5*IQR): {outlier_threshold_upper_spark:.2f}\")\n",
        "    print(f\"Batas Bawah Outlier (1.5*IQR): {outlier_threshold_lower_spark:.2f}\")\n",
        "\n",
        "    # Filter data untuk mendapatkan baris yang dianggap outlier di SELURUH Spark DataFrame\n",
        "    outliers_spark_df = spark_df.filter(\n",
        "        (col('bmi') > outlier_threshold_upper_spark) |\n",
        "        (col('bmi') < outlier_threshold_lower_spark)\n",
        "    )\n",
        "\n",
        "    print(f\"\\nJumlah outliers BMI di Spark DataFrame (berdasarkan 1.5*IQR, dihitung terdistribusi): {outliers_spark_df.count()}\")\n",
        "\n",
        "    # Tampilkan sampel outliers (hati-hati jika jumlah outlier masih sangat banyak)\n",
        "    print(\"\\nSampel 5 baris data yang dianggap outliers BMI:\")\n",
        "    outliers_spark_df.show(5)\n",
        "\n",
        "except Exception as e:\n",
        "     print(f\"Gagal menghitung kuartil dan mendeteksi outliers: {e}\")\n",
        "     print(\"Pastikan kolom 'bmi' ada dan berisi nilai numerik.\")\n",
        "\n",
        "\n",
        "# Visualisasi Box Plot dari Big Data:\n",
        "# Seperti histogram, box plot langsung dari seluruh data mentah tidak umum.\n",
        "# Spark DataFrame .summary() menghasilkan min, Q1, median, Q3, max (aproksimasi) yang bisa\n",
        "# digunakan untuk MENGGAMBAR box plot tunggal (merepresentasikan seluruh distribusi),\n",
        "# tapi bukan visualisasi setiap titik data.\n",
        "\n",
        "# spark_df.summary().select('summary', 'bmi', 'bp', 'target').show() # Lihat ringkasan untuk box plot\n",
        "# Kumpulkan baris summary ini (hanya 5 baris) ke Pandas dan gambar box plot dari angka-angka tersebut."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Contoh 5: Deteksi Outliers (Spark DataFrame di Data Terdistribusi) ---\n",
            "\n",
            "Menghitung Q1 dan Q3 untuk BMI secara aproksimasi di Spark...\n",
            "Q1 BMI (Spark Aproksimasi): -0.03\n",
            "Q3 BMI (Spark Aproksimasi): 0.03\n",
            "IQR BMI: 0.07\n",
            "Batas Atas Outlier (1.5*IQR): 0.14\n",
            "Batas Bawah Outlier (1.5*IQR): -0.14\n",
            "\n",
            "Jumlah outliers BMI di Spark DataFrame (berdasarkan 1.5*IQR, dihitung terdistribusi): 29708\n",
            "\n",
            "Sampel 5 baris data yang dianggap outliers BMI:\n",
            "+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+------+\n",
            "|                 age|                 sex|                bmi|                  bp|                  s1|                  s2|                  s3|                 s4|                  s5|                 s6|target|\n",
            "+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+------+\n",
            "|-0.04910501639104307|-0.04464163650698...|0.16085491731571683|                NULL|-0.02908801698423...|-0.01978963667180...|-0.04708248345611185|0.03430885887772673| 0.02802037249332928| 0.0113486232440374| 346.0|\n",
            "|-0.04547247794002...| 0.05068011873981862|0.13714305169033927|-0.01599897522030...|0.041085578784023497| 0.03187985952347199|-0.04340084565202491|0.07120997975363674| 0.07101867000452176| 0.0486275854775475| 233.0|\n",
            "|-0.00914709342982...| 0.05068011873981862|0.17055522598064407|0.014986683562338177|0.030077955918414535| 0.03375875029420919|-0.02131101882750326|0.03430885887772673|0.033653814906286016|0.03205915781820968| 242.0|\n",
            "|-0.04910501639104307|-0.04464163650698...|0.16085491731571683|-0.04698463400294853|-0.02908801698423...|-0.01978963667180...|-0.04708248345611185|0.03430885887772673| 0.02802037249332928| 0.0113486232440374| 346.0|\n",
            "|-0.04547247794002...| 0.05068011873981862|0.13714305169033927|-0.01599897522030...|0.041085578784023497| 0.03187985952347199|-0.04340084565202491|0.07120997975363674| 0.07101867000452176| 0.0486275854775475| 233.0|\n",
            "+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGqPPyC0biie",
        "outputId": "8797289b-f08d-4149-960e-0bf060c2367d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**Contoh Program 6: Teknik Sampling (Menggunakan Spark DataFrame)**\n",
        "\n",
        "Spark menyediakan fungsi bawaan untuk mengambil sampel data secara terdistribusi."
      ],
      "metadata": {
        "id": "LWsDh43Gbiif"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Contoh 6: Teknik Sampling (Spark DataFrame di Data Terdistribusi) ---\")\n",
        "\n",
        "# Random Sampling: Ambil fraksi (persentase) dari SELURUH Spark DataFrame secara acak\n",
        "# fraction=0.1 berarti 10% dari data\n",
        "spark_df_sample_random = spark_df.sample(withReplacement=False, fraction=0.1, seed=42) # withReplacement=False: tanpa pengembalian\n",
        "\n",
        "print(f\"\\nUkuran Spark DataFrame asli (dihitung terdistribusi): {spark_df.count()} baris\")\n",
        "print(f\"Ukuran sampel acak Spark DataFrame (sekitar 10%, dihitung terdistribusi): {spark_df_sample_random.count()} baris\")\n",
        "print(\"Sampel acak Spark DataFrame 5 baris pertama:\")\n",
        "spark_df_sample_random.show(5)\n",
        "\n",
        "# Stratified Sampling: Mengambil sampel per kategori di Spark DataFrame\n",
        "# Dataset diabetes tidak punya kolom kategori yang jelas.\n",
        "# Konsepnya: Tentukan kolom strata, tentukan fraksi per strata.\n",
        "# Contoh jika ada kolom 'gender' (tidak runnable dengan data diabetes):\n",
        "# strata_fractions = {\"Male\": 0.05, \"Female\": 0.03, \"Unknown\": 0.1} # Fraksi sampel per strata\n",
        "# spark_df_sample_stratified = spark_df.sampleBy(\"gender\", fractions=strata_fractions, seed=42)\n",
        "# print(\"\\nUkuran sampel stratifikasi per gender:\")\n",
        "# spark_df_sample_stratified.groupBy(\"gender\").count().show()\n",
        "\n",
        "# Mengumpulkan Sampel ke Pandas untuk EDA/Visualisasi Detail\n",
        "# Ini langkah yang umum dilakukan SETELAH sampling di Spark.\n",
        "# HATI-HATI: Pastikan ukuran sampel CUKUP KECIL untuk dimuat di memori driver.\n",
        "sample_size_for_pandas = 1000 # Tentukan ukuran maksimum sampel yang ingin diolah di Pandas\n",
        "print(f\"\\nMengambil {sample_size_for_pandas} baris sampel acak ke Pandas untuk EDA detail...\")\n",
        "# Ambil sampel acak lagi jika sampel sebelumnya masih terlalu besar\n",
        "spark_df_small_sample = spark_df.sample(withReplacement=False, fraction=min(1.0, sample_size_for_pandas / spark_df.count()), seed=123) # Ambil fraksi yang sesuai atau 1.0 jika data asli lebih kecil\n",
        "\n",
        "try:\n",
        "    df_sample_for_pandas = spark_df_small_sample.toPandas()\n",
        "    print(f\"Sampel berukuran {len(df_sample_for_pandas)} baris berhasil dikumpulkan ke Pandas DataFrame.\")\n",
        "    print(\"\\nSampel di Pandas:\")\n",
        "    print(df_sample_for_pandas.head())\n",
        "\n",
        "    # Sekarang bisa melakukan EDA detail dan visualisasi interaktif pada df_sample_for_pandas\n",
        "    # menggunakan Pandas, Matplotlib, Seaborn seperti contoh program Python sebelumnya.\n",
        "    # Misalnya: df_sample_for_pandas['bmi'].hist(), sns.scatterplot(x='bmi', y='target', data=df_sample_for_pandas)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Gagal mengumpulkan sampel kecil ke Pandas: {e}\")\n",
        "    print(\"Ukuran sampel mungkin masih terlalu besar untuk memori driver.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Contoh 6: Teknik Sampling (Spark DataFrame di Data Terdistribusi) ---\n",
            "\n",
            "Ukuran Spark DataFrame asli (dihitung terdistribusi): 4420000 baris\n",
            "Ukuran sampel acak Spark DataFrame (sekitar 10%, dihitung terdistribusi): 442494 baris\n",
            "Sampel acak Spark DataFrame 5 baris pertama:\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "|                 age|                 sex|                 bmi|                  bp|                  s1|                  s2|                  s3|                  s4|                  s5|                  s6|target|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "| 0.06350367559055897| 0.05068011873981862|-0.00189470584028...|  0.0666294482000771| 0.09061988167926385| 0.10891438112369757|0.022868634821540033| 0.01770335448356722| -0.0358161925842373|0.003064409414368...|  63.0|\n",
            "|-0.00551455497881...|-0.04464163650698...|  0.0422955891888289|0.049415193320830796|0.024574144485610048|-0.02386056667506523| 0.07441156407875721|-0.03949338287409329| 0.05227699103843915|0.027917050903375224| 166.0|\n",
            "|-0.03820740103798481|-0.04464163650698...|-0.01051720243133...|-0.03665608107540074|-0.03734373413344...|-0.01947648821001...|-0.02867429443567...|-0.00259226199818...|-0.01811369231569...|-0.01764612515980379|  97.0|\n",
            "|  0.0344433679824036|-0.04464163650698...|-0.00728376620968...|0.014986683562338177|-0.04422349842444599|-0.03732595053201525|-0.00290282980706...|-0.03949338287409329|-0.02139530925527...|0.007206516329202944| 155.0|\n",
            "| 0.04170844488444244|-0.04464163650698...|-0.06440780612537028| 0.03564378941743375| 0.01219056876179996|-0.05799374901012452| 0.18117906039727852| -0.0763945037500033|-6.11735304562621...|-0.05078298047847944| 170.0|\n",
            "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Mengambil 1000 baris sampel acak ke Pandas untuk EDA detail...\n",
            "Sampel berukuran 972 baris berhasil dikumpulkan ke Pandas DataFrame.\n",
            "\n",
            "Sampel di Pandas:\n",
            "        age       sex       bmi        bp        s1        s2        s3  \\\n",
            "0  0.038076  0.050680 -0.013751 -0.015999 -0.035968 -0.021982 -0.013948   \n",
            "1 -0.052738 -0.044642 -0.009439 -0.005670  0.039710  0.044719  0.026550   \n",
            "2 -0.067268 -0.044642 -0.059019  0.032201 -0.051103 -0.049539 -0.010266   \n",
            "3 -0.045472 -0.044642 -0.073030 -0.081413  0.083740  0.027809  0.173816   \n",
            "4 -0.052738 -0.044642  0.054152 -0.026328 -0.055231 -0.033881 -0.013948   \n",
            "\n",
            "         s4        s5        s6  target  \n",
            "0 -0.002592 -0.025953 -0.001078    83.0  \n",
            "1 -0.002592 -0.018114 -0.013504    59.0  \n",
            "2 -0.039493  0.002004  0.023775    86.0  \n",
            "3 -0.039493 -0.004222  0.003064    57.0  \n",
            "4 -0.039493 -0.074093 -0.059067   142.0  \n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcW4coEhbiif",
        "outputId": "764d6eee-71e8-4b41-f594-c679aab54fb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**--- Menghentikan Spark Session ---**\n",
        "Setelah selesai dengan semua operasi Spark, penting untuk menghentikan Spark Session."
      ],
      "metadata": {
        "id": "ms5y5NHobiig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMenghentikan Spark Session...\")\n",
        "spark.stop()\n",
        "print(\"Spark Session dihentikan.\")\n",
        "\n",
        "# Hapus file sintetis jika belum\n",
        "if os.path.exists(parquet_path):\n",
        "     try:\n",
        "         os.remove(parquet_path)\n",
        "     except OSError as e:\n",
        "         print(f\"Error removing file {parquet_path}: {e}\")\n",
        "\n",
        "# Jika Spark membuat direktori (seperti untuk Parquet), mungkin perlu penghapusan direktori\n",
        "# import shutil\n",
        "# if os.path.exists(parquet_path):\n",
        "#     try:\n",
        "#         shutil.rmtree(parquet_path)\n",
        "#     except OSError as e:\n",
        "#         print(f\"Error removing directory {parquet_path}: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Menghentikan Spark Session...\n",
            "Spark Session dihentikan.\n"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GXvculdbiig",
        "outputId": "13f27da7-a8e4-43ee-92e3-433b338d6daf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Penjelasan Detail:**\n",
        "\n",
        "1.  **Inisialisasi Spark Session:** Baris `spark = SparkSession.builder...getOrCreate()` membuat objek SparkSession, yang merupakan titik masuk ke semua fungsionalitas Spark. `master(\"local[*]\")` berarti menjalankan Spark di mesin lokal menggunakan semua core CPU yang tersedia (untuk klaster, ini akan menjadi URL master).\n",
        "2.  **Dataset Sintetis:** Kita tidak bisa langsung memuat dataset kecil dari scikit-learn ke Spark DataFrame dengan cara yang relevan untuk \"Big Data\". Jadi, kita mereplikasi data asli ribuan kali di Pandas, lalu menyimpulkan missing values, dan menyimpannya ke format Parquet. Spark sangat efisien dalam membaca format Parquet dari sistem file terdistribusi atau lokal.\n",
        "3.  **Load ke Spark DataFrame:** `spark.read.parquet(parquet_path)` adalah cara Spark membaca data dari file (dalam hal ini Parquet) ke dalam struktur DataFrame-nya. Spark secara otomatis menangani partisi data di seluruh klaster.\n",
        "4.  **Operasi Spark DataFrame:** Semua metode yang digunakan (`.describe()`, `.summary()`, `.select()`, `.filter()`, `.groupBy()`, `.agg()`, `.count()`, `.stat.corr()`, `.na.drop()`, `.na.fill()`, `.sample()`, `.sampleBy()`) adalah bagian dari Spark DataFrame API atau Spark SQL. *Setiap* operasi ini (kecuali `show()` dan `collect()` jika hasilnya kecil) dieksekusi secara *terdistribusi* di seluruh worker node di klaster Spark. Anda tidak perlu khawatir tentang looping data baris per baris; Spark yang mengurusnya.\n",
        "5.  **`show()` vs `collect()`:**\n",
        "    * `.show()`: Hanya menampilkan *beberapa* baris pertama (default 20). Ini hanya untuk pratinjau cepat data di layar driver dan tidak memuat seluruh data.\n",
        "    * `.collect()`: Mengumpulkan *seluruh* hasil dari operasi terdistribusi ke driver node sebagai list objek Python. **Gunakan dengan HATI-HATI**! Jika hasilnya besar, ini akan menghabiskan memori driver dan crash. Contoh seperti `spark_df.select(avg('bmi')).collect()` aman karena hasilnya hanya satu nilai. Mengumpulkan `bmi_hist_spark.toPandas()` juga umumnya aman karena hasil agregasi biasanya jauh lebih kecil dari data asli. Mengumpulkan seluruh `spark_df.toPandas()` *tidak* aman untuk Big Data.\n",
        "6.  **Visualisasi:** Spark tidak memiliki library visualisasi built-in seperti Matplotlib atau Seaborn. Visualisasi biasanya dilakukan:\n",
        "    * Dengan mengumpulkan hasil agregasi atau sampel kecil ke Pandas dan menggunakan library standar.\n",
        "    * Menggunakan tools Business Intelligence (BI) seperti Tableau, Superset, Power BI yang memiliki konektor Spark dan dapat mendorong komputasi visualisasi ke backend Spark.\n",
        "    * Menggunakan library visualisasi spesifik Big Data (seperti Datashader) yang bekerja dengan backend terdistribusi.\n",
        "    Contoh di atas menunjukkan cara menyiapkan data (agregasi atau sampling) di Spark, lalu menjelaskan langkah selanjutnya yaitu visualisasi di luar Spark.\n",
        "7.  **Approximate Quantiles:** Karena mengurutkan Big Data untuk mendapatkan persentil eksak sangat mahal, Spark menyediakan fungsi `approxQuantile` yang menghitung estimasi dengan toleransi kesalahan yang ditentukan. Ini adalah praktik umum di Big Data EDA untuk statistik berbasis urutan.\n",
        "8.  **Menghentikan Spark:** `spark.stop()` penting untuk membersihkan sumber daya klaster setelah pekerjaan selesai.\n",
        "\n",
        "Contoh-contoh ini menunjukkan bagaimana konsep EDA yang sama diterapkan menggunakan framework yang dirancang untuk Big Data (Spark), menyoroti perbedaan mendasar dalam eksekusi (terdistribusi vs. in-memory) dibandingkan dengan Pandas."
      ],
      "metadata": {
        "id": "aFSQ-PG-biih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"md-recitation\">\n",
        "  Sources\n",
        "  <ol>\n",
        "  <li><a href=\"https://subscription.packtpub.com/book/data/9781789806311/1/ch01lvl1sec10/highlighting-outliers\">https://subscription.packtpub.com/book/data/9781789806311/1/ch01lvl1sec10/highlighting-outliers</a></li>\n",
        "  </ol>\n",
        "</div>"
      ],
      "metadata": {
        "id": "1v7c_rmnbiih"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}